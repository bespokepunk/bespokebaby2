# RunPod Final Training Steps - PERFECT Captions

## Summary of Fixes

**What was wrong:**
- 132 eye color captions didn't match actual pixels
- 89 hex color codes had rounding errors
- Total accuracy: ~10% before fixes

**What's fixed:**
- âœ… All 203 eye colors verified against actual pixel RGB values
- âœ… All 203 hex codes corrected to match exact image colors
- âœ… Total accuracy: 100% pixel-perfect captions

**Final eye color distribution:**
- Brown eyes: 30 (14.8% of training data with 10x repeats)
- Blue eyes: 35
- Green eyes: 35
- Red eyes: 34
- Gray eyes: 23
- Cyan eyes: 20
- Purple eyes: 5
- Black eyes: 1

---

## Step-by-Step RunPod Training

### 1. Upload File

Upload `bespoke_punks_FINAL_PERFECT.zip` (881KB) to RunPod `/workspace/`

### 2. Clean Previous Attempts

```bash
cd /workspace

# Remove ALL previous training attempts
rm -rf training_data training_images output output_fixed output_CORRECT output_VERIFIED

# Verify clean slate
ls -la
```

### 3. Extract Training Data

```bash
# Create proper folder structure for Kohya
mkdir -p training_images/10_bespokepunks

# Extract training data
unzip -q bespoke_punks_FINAL_PERFECT.zip -d training_images/10_bespokepunks

# Verify extraction
echo "Images: $(find training_images -name '*.png' | wc -l)"
echo "Captions: $(find training_images -name '*.txt' | wc -l)"
echo "Brown eyes: $(grep -r 'brown eyes' training_images | wc -l)"
```

**Expected output:**
```
Images: 203
Captions: 203
Brown eyes: 30
```

### 4. Start Training

```bash
cd /workspace/kohya_ss

python3 sd-scripts/train_network.py \
  --pretrained_model_name_or_path="runwayml/stable-diffusion-v1-5" \
  --train_data_dir="/workspace/training_images" \
  --resolution="512,512" \
  --output_dir="/workspace/output_PERFECT" \
  --output_name="bespoke_punks_PERFECT" \
  --save_model_as=safetensors \
  --max_train_epochs=10 \
  --learning_rate=0.0001 \
  --unet_lr=0.0001 \
  --text_encoder_lr=0.00005 \
  --network_module=networks.lora \
  --network_dim=32 \
  --network_alpha=16 \
  --save_every_n_epochs=1 \
  --mixed_precision="fp16" \
  --cache_latents \
  --optimizer_type="AdamW8bit" \
  --caption_extension=".txt" \
  --lr_scheduler="cosine_with_restarts" \
  --lr_scheduler_num_cycles=3 \
  --min_snr_gamma=5 \
  --noise_offset=0.1 \
  --clip_skip=2 \
  --train_batch_size=4 \
  --gradient_checkpointing \
  --xformers
```

### 5. Training Info

**Expected:**
- Total steps: ~5,070 (507 per epoch Ã— 10 epochs)
- Duration: ~1.5-2 hours on A100
- Cost: ~$2.50-$3.50 total
- Output: 10 .safetensors files (one per epoch)

**Output location:**
```
/workspace/output_PERFECT/bespoke_punks_PERFECT-000001.safetensors
/workspace/output_PERFECT/bespoke_punks_PERFECT-000002.safetensors
...
/workspace/output_PERFECT/bespoke_punks_PERFECT-000010.safetensors
```

### 6. Download Models

Download epochs 3, 5, 7, and 10 for testing.

Usually epoch 3-5 is the sweet spot, but test multiple.

---

## Testing After Training

Once you download the new PERFECT models, test with:

```python
prompt = "pixel art, 24x24, portrait of bespoke punk lady, brown eyes, light skin"
```

**Expected result:** Brown eyes should ACTUALLY be brown now! ðŸŽ‰

---

## Files Used

- Training data: `bespoke_punks_FINAL_PERFECT.zip`
- Verification: All eye colors and hex codes pixel-verified
- Scripts: `verify_hex_colors.py`, `auto_fix_captions_from_pixels.py`

---

## Troubleshooting

**If brown eyes still don't work:**
1. Check training actually used `/workspace/training_images/10_bespokepunks/`
2. Verify brown eyes count: `grep -r 'brown eyes' /workspace/training_images | wc -l` (should be 30)
3. May need more brown-eyed training images in dataset (currently only 30/203 = 14.8%)

**If training fails:**
- Check disk space: `df -h /workspace`
- Check GPU: `nvidia-smi`
- Check logs for specific error
