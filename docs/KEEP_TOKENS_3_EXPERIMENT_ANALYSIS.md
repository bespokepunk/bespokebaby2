# Keep Tokens = 3 Experiment - Comprehensive Analysis

**Experiment:** SD15_KEEP_TOKENS_3_EXPERIMENT
**Date:** 2025-11-10
**Training Config:** keep_tokens=3, caption_dropout_rate=0.05, network_dim=32
**Epochs Tested:** 1-10
**Dataset:** 203 images with CORRECTED captions

---

## Executive Summary

### Main Findings

1. **‚ùå keep_tokens=3 hypothesis REJECTED**: Background fix appeared at **Epoch 9** (vs Epoch 7 in previous run with keep_tokens=1). **DELAYED by 2 epochs** instead of accelerating.

2. **‚úÖ Root cause identified**: Caption hex codes are **INCORRECT** - multiple features share the same color codes, confusing spatial color placement.

3. **‚úÖ Best checkpoint**: **Epoch 9** (301 unique colors, green background, clean skin) - NOT Epoch 10 which regressed to 502 colors.

4. **‚úÖ Green bleeding confirmed**: Caused by caption errors where `hair (#03dc73)` and `background (#03dc73)` share the SAME hex code.

---

## Epoch-by-Epoch Results

| Epoch | BG Color | Unique Colors | Color Accuracy | Visual Score | Key Observation |
|-------|----------|---------------|----------------|--------------|-----------------|
| 1 | Black | 435 | 0.00% | 5/10 | Baseline - noisy |
| 2 | Pink | 410 | 1.90% | 5/10 | Starting to learn |
| 3 | Pink | 384 | 0.00% | 7/10 | Quality‚Üë but oscillating |
| 4 | Pink | 455 | **38.48%** | 5/10 | Huge spike then regress |
| 5 | Pink | 418 | 0.00% | 5/10 | Regression |
| 6 | Pink/Red | 342 | 0.00% | 7/10 | Getting cleaner |
| 7 | Pink (green face) | 532 | 0.00% | 5/10 | Green bleeding into face! |
| 8 | Purple | 342 | 0.00% | 6/10 | Green still in face/necklace |
| **9** | **GREEN ‚úÖ** | **301** | **0.49%** | **6/10** | **BREAKTHROUGH** |
| 10 | Green | 502 | 0.24% | 6/10 | Regressed (noisier) |

### Critical Pattern: Epochs 7-9

- **Epoch 7**: Green appears in FACE/SKIN (wrong location)
- **Epoch 8**: Green in face/necklace (still wrong)
- **Epoch 9**: Green FINALLY in background (correct!) ‚úÖ

**This confirms your hypothesis:** The model IS learning green, but caption errors caused it to associate green with the wrong spatial regions first.

---

## Root Cause Analysis

### üîç Caption Hex Code Errors Discovered

**Example from `lady_074_melon.txt`:**
```
hair (#03dc73), ...bright green background (#03dc73)
```

**THE PROBLEM:**
- Hair color: `#03dc73` (bright green)
- Background color: `#03dc73` (bright green)
- **SAME COLOR FOR DIFFERENT FEATURES!**

**Result:** Model cannot learn spatial color placement because captions explicitly say green belongs to BOTH hair AND background.

### Additional Caption Issues

1. **Uncaptioned hex codes at end**:
   ```
   ...palette: #03dc73, #2c1600, #efbda4, #000000, sharp pixel edges,
   hard color borders, retro pixel art style, #f7d7c0, #ecf0cf, #a68167,
   #fdfef0, #658f9d, #583b2d, #966d51, #a17c62
   ```
   - Extra hex codes (#f7d7c0, #ecf0cf, etc.) have NO descriptive context
   - This creates noise and confuses learning
   - Contributes to high unique color count (300-500 vs ideal 20-100)

2. **Palette section placement**:
   - Comes AFTER all descriptive text
   - May not reinforce color-feature associations strongly enough

---

## Hypothesis Validation

### Hypothesis 1: keep_tokens=3 Will Accelerate Background Fix

**Prediction:** Background would turn green by Epoch 3-4 (vs Epoch 7 previously)

**Result:** ‚ùå **REJECTED**
- Background turned green at **Epoch 9** (2 epochs SLOWER than previous Epoch 7)
- keep_tokens=3 appears to have DELAYED learning, not accelerated it

**Possible explanation:**
- With keep_tokens=3, more tokens are protected from dropout
- This may have REDUCED the beneficial regularization effect
- Caption dropout at 5% may have been too high with keep_tokens=3

### Hypothesis 2: Green Bleeding Due to Caption Hex Code Placement

**Prediction:** Green appearing in face/skin instead of background

**Result:** ‚úÖ **VALIDATED**
- Epoch 7: Green in face/skin
- Epoch 8: Green in face/necklace
- Epoch 9: Green finally in background
- **Root cause:** Captions assign same hex code to multiple features

---

## Training Stability Analysis

**Oscillation Detected:**
- Color accuracy: 0% ‚Üí 38% ‚Üí 0% ‚Üí 0% (highly unstable)
- Unique colors: 435 ‚Üí 384 ‚Üí 455 ‚Üí 418 (oscillating)

**Epoch 10 Regression:**
- Epoch 9: 301 colors (cleanest)
- Epoch 10: 502 colors (67% INCREASE in noise!)
- **Conclusion:** Training peaked at Epoch 9, then regressed

**Recommendation:** Future runs should stop at Epoch 9 or implement early stopping.

---

## Quantitative Metrics Summary

### Best Epoch: Epoch 9

**Strengths:**
- ‚úÖ Green background (correct)
- ‚úÖ Normal skin tone (no green bleeding)
- ‚úÖ Lowest unique color count (301)
- ‚úÖ Stable structure

**Weaknesses:**
- ‚ö†Ô∏è Hair still noisy (scattered pink/purple pixels)
- ‚ö†Ô∏è 301 colors still HIGH for pixel art (ideal: 20-100)
- ‚ö†Ô∏è Color accuracy metrics broken (false negatives)

---

## Next Training Run Recommendations

### Priority 1: Fix Caption Hex Codes (CRITICAL)

**Problem:** Features share hex codes (e.g., hair AND background both #03dc73)

**Solution:** Audit ALL 203 caption files and ensure:
1. Each feature has UNIQUE hex code (no overlaps)
2. Background colors don't appear in other features
3. Feature colors match actual pixel analysis

**Example fix for lady_074_melon.txt:**
```
BEFORE:
hair (#03dc73), ...bright green background (#03dc73)

AFTER:
hair (#ff66cc), ...bright green background (#03dc73)
```

**Estimated impact:** üî• **CRITICAL** - This is likely the #1 cause of color bleeding and slow convergence.

### Priority 2: Remove Uncaptioned Hex Codes

**Problem:** Extra hex codes at end with no context
```
...#f7d7c0, #ecf0cf, #a68167, #fdfef0, #658f9d...
```

**Solution:** Remove ALL uncaptioned hex codes after "retro pixel art style"

**Rationale:**
- Reduces noise
- Forces model to learn from labeled colors only
- Should reduce unique color count (currently 300-500)

**Estimated impact:** üî• **HIGH** - Should significantly improve color purity

### Priority 3: Revert keep_tokens to 1

**Finding:** keep_tokens=3 DELAYED background fix (Epoch 9 vs Epoch 7)

**Solution:** Return to `keep_tokens=1` in next training

**Rationale:**
- Previous run with keep_tokens=1 achieved green background at Epoch 7
- keep_tokens=3 delayed to Epoch 9
- More tokens protected = less regularization = slower learning

**Estimated impact:** üü° **MEDIUM** - May accelerate convergence by 2 epochs

### Priority 4: Reduce Caption Dropout (Optional)

**Current:** caption_dropout_rate=0.05 (5%)

**Proposed:** caption_dropout_rate=0.02 (2%)

**Rationale:**
- With keep_tokens=1, some dropout is beneficial
- But 5% may be too aggressive
- 2% provides regularization without excessive randomness

**Estimated impact:** üü¢ **LOW-MEDIUM** - Conservative tuning

### Priority 5: Early Stopping at Epoch 9

**Finding:** Epoch 10 regressed (301 ‚Üí 502 colors)

**Solution:** Configure training to stop at Epoch 9, OR implement early stopping based on unique color count

**Rationale:**
- Prevents overfitting/regression
- Saves compute time (~10% faster)

**Estimated impact:** üü¢ **LOW** - Efficiency gain, prevents regression

---

## What NOT to Change

### ‚úÖ Keep These Parameters:

1. **network_dim=32** - Proven optimal for pixel art (not photorealistic)
2. **Training dataset (203 images)** - Good size, just needs caption fixes
3. **Batch size=4, gradient_accumulation=1** - A100 optimization working well
4. **mixed_precision=bf16** - A100 native, good performance
5. **Dual caption placement (adjacent + palette)** - Structure is fine, just need correct hex codes

---

## Proposed Next Training Configuration

```toml
# training_config_SD15_CAPTION_FIX.toml

[general]
pretrained_model_name_or_path = "runwayml/stable-diffusion-v1-5"
train_data_dir = "/workspace/training_data/10_bespoke_baby"
output_dir = "/workspace/output"
output_name = "bespoke_baby_sd15_lora_caption_fix"

[training]
max_train_epochs = 9  # Stop at Epoch 9 (not 10)
train_batch_size = 4
gradient_accumulation_steps = 1
mixed_precision = "bf16"

[dataset]
keep_tokens = 1  # REVERTED from 3
caption_dropout_rate = 0.02  # REDUCED from 0.05

[network]
network_module = "networks.lora"
network_dim = 32  # KEEP (proven optimal)
network_alpha = 16  # KEEP

[optimizer]
optimizer_type = "AdamW8bit"
learning_rate = 1e-4  # KEEP
lr_scheduler = "cosine"  # KEEP
```

---

## Action Items for Next Training Run

### üî• CRITICAL (Must Do):

1. **Audit and fix all 203 caption files**:
   - Scan for duplicate hex codes across features
   - Ensure background hex codes are UNIQUE (not used for hair/clothing/etc)
   - Verify hex codes match actual pixel colors in images

2. **Remove uncaptioned hex codes**:
   - Delete all hex codes after "retro pixel art style"
   - Keep only labeled hex codes (adjacent to feature names)

### üü° RECOMMENDED (Should Do):

3. **Revert keep_tokens to 1** in training config

4. **Reduce caption_dropout_rate to 0.02** in training config

5. **Set max_train_epochs to 9** to prevent Epoch 10 regression

### üü¢ OPTIONAL (Consider):

6. Implement early stopping based on unique color count threshold

7. Add validation set (20-30 images) to monitor overfitting

---

## Expected Improvements in Next Run

**If caption fixes are applied correctly:**

‚úÖ **Green background should appear by Epoch 5-7** (vs Epoch 9)
‚úÖ **No green bleeding into face/skin** (root cause fixed)
‚úÖ **Unique colors should drop to 150-250 range** (vs 300-500)
‚úÖ **Hair color consistency improved** (no scattered pixels)
‚úÖ **Faster convergence overall** (keep_tokens=1 + lower dropout)

**Success Criteria:**
- Background GREEN by Epoch 7
- Unique colors < 250
- No color bleeding across features
- Stable training (no oscillation)

---

## Conclusion

The keep_tokens=3 experiment provided valuable insights:

1. **keep_tokens=3 is NOT beneficial** - delayed convergence
2. **Caption hex code errors are the ROOT CAUSE** of color bleeding and slow learning
3. **Epoch 9 is optimal stopping point** - Epoch 10 regresses
4. **High unique color count (300-500) indicates caption noise** from uncaptioned hex codes

**Bottom line:** The next training run should focus on **caption quality** (fix hex codes, remove noise) rather than hyperparameter tuning. The training parameters are already well-optimized - it's the data quality that needs improvement.

**Estimated time to fix captions:** 2-4 hours manual audit + scripting
**Estimated next training time:** ~30-40 minutes (9 epochs on A100)
**Expected result:** Clean, accurate pixel art with correct background colors by Epoch 7
