# ============================================================================
# SD15 LoRA Training Config - CAPTION FIX EXPERIMENT
# ============================================================================
#
# CHANGES FROM keep_tokens=3 EXPERIMENT:
#   - Reverted keep_tokens: 3 → 1 (3 was SLOWER - green bg at Epoch 9 vs 7)
#   - Reduced caption_dropout_rate: 0.05 → 0.02 (less aggressive)
#   - Reduced max_epochs: 10 → 9 (Epoch 10 regressed in previous run)
#   - ✨ CRITICAL: ALL hex codes removed from captions (fixes duplicate/wrong codes)
#
# ROOT CAUSE FIXED:
#   - Problem: Features shared hex codes (e.g. hair AND background both #03dc73)
#   - Solution: Removed ALL 3,621 hex codes from 203 caption files
#   - Result: Clean descriptive text + model learns from actual pixels
#
# Expected Improvements:
#   - Green background by Epoch 5-7 (vs Epoch 9 with keep_tokens=3)
#   - No color bleeding (duplicate hex codes eliminated)
#   - Unique colors < 250 (vs 300-500 with hex code noise)
#   - Faster, cleaner convergence
# ============================================================================

[general]
enable_bucket = true
bucket_resolution = 512
min_bucket_reso = 256
max_bucket_reso = 1024
bucket_no_upscale = true

[model_arguments]
pretrained_model_name_or_path = "runwayml/stable-diffusion-v1-5"
v2 = false
v_parameterization = false

[network_arguments]
network_module = "networks.lora"
network_dim = 32              # KEEP - proven optimal for pixel art
network_alpha = 16            # KEEP
network_train_unet_only = false
network_train_text_encoder_only = false

[training_arguments]
output_dir = "/workspace/output"
output_name = "bespoke_baby_sd15_lora_phase1b"
save_precision = "fp16"
save_model_as = "safetensors"

# Training settings
max_train_epochs = 8              # OPTIMAL - stop before degradation
train_batch_size = 4              # KEEP - A100 optimization
gradient_accumulation_steps = 1   # KEEP - effective batch = 4
mixed_precision = "bf16"          # KEEP - A100 native precision
xformers = true
sdpa = false

# Optimizer settings
optimizer_type = "AdamW"
learning_rate = 1e-4          # KEEP - stable, proven value
unet_lr = 1e-4
text_encoder_lr = 5e-5
lr_scheduler = "cosine_with_restarts"
lr_warmup_steps = 100
lr_scheduler_num_cycles = 3

# Dataset settings
train_data_dir = "/workspace/runpod_package_phase1b/training_data"
resolution = "512,512"
shuffle_caption = true
keep_tokens = 1               # ★ REVERTED: 3 → 1 (3 was slower)
caption_dropout_rate = 0.02   # ★ REDUCED: 0.05 → 0.02 (less aggressive)
caption_dropout_every_n_epochs = 0
max_token_length = 225
caption_extension = ".txt"

# Regularization
prior_loss_weight = 1.0
min_snr_gamma = 5.0

# Logging and saving
logging_dir = "/workspace/logs"
log_prefix = "caption_fix_experiment"
save_every_n_epochs = 1       # Save all epochs for analysis
save_state = true

# Memory optimization
gradient_checkpointing = true
cache_latents = true
cache_latents_to_disk = false

# Augmentation settings
noise_offset = 0.05           # Light noise offset for diversity
multires_noise_iterations = 6
multires_noise_discount = 0.3

# Reproducibility
seed = 42

# ============================================================================
# NOTES FOR MLOps TRACKING:
# ============================================================================
# Run Name: SD15_CAPTION_FIX_EXPERIMENT
# Caption Version: cleaned_no_hex_codes_v1
# Training Dataset: 203 original images
# Caption Changes: Removed ALL 3,621 hex codes (fixed duplicates/wrong codes)
#
# Key Parameters to Track:
#   - architecture.network_dim: 32
#   - architecture.network_alpha: 16
#   - hyperparameters.learning_rate: 1e-4
#   - hyperparameters.max_train_epochs: 9 (not 10)
#   - data.keep_tokens: 1 (reverted from 3)
#   - data.caption_dropout_rate: 0.02 (reduced from 0.05)
#   - data.num_images: 203
#   - data.hex_codes_in_captions: 0 (removed all)
#
# Quality Checkpoints:
#   - Epoch 1-2: Expect pixel art style, possibly wrong background (baseline)
#   - Epoch 5-7: GREEN BACKGROUND should appear (earlier than Epoch 9)
#   - Epoch 8-9: Production quality (target 8-9/10)
#
# Success Criteria:
#   - Green background by Epoch 7 (vs Epoch 9 in keep_tokens=3)
#   - No color bleeding across features
#   - Unique colors < 250 (vs 300-500 previously)
#   - Stable training (no oscillation)
#
# Comparison Baselines:
#   - SD15_KEEP_TOKENS_3: Best Epoch 9 (301 colors, green bg but delayed)
#   - SD15_FINAL_CORRECTED: Best Epoch 7 (green bg appeared)
#   - SD15_PERFECT: Epoch 7 (9/10 production ready)
# ============================================================================
